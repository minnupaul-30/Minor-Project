{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from preds.ipynb\n",
      "importing Jupyter notebook from Captcha_seg.ipynb\n",
      "1080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bg/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 864 samples, validate on 216 samples\n",
      "Epoch 1/20\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 3.5885 - acc: 0.0313 - val_loss: 3.5801 - val_acc: 0.0417\n",
      "Epoch 2/20\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 3.4292 - acc: 0.0949 - val_loss: 3.1841 - val_acc: 0.1157\n",
      "Epoch 3/20\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 2.4552 - acc: 0.3021 - val_loss: 2.3841 - val_acc: 0.3056\n",
      "Epoch 4/20\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.6329 - acc: 0.5197 - val_loss: 1.8587 - val_acc: 0.5000\n",
      "Epoch 5/20\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.1236 - acc: 0.6713 - val_loss: 1.7316 - val_acc: 0.4861\n",
      "Epoch 6/20\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 0.7415 - acc: 0.7755 - val_loss: 1.5620 - val_acc: 0.5741\n",
      "Epoch 7/20\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.4900 - acc: 0.8414 - val_loss: 1.5585 - val_acc: 0.5833\n",
      "Epoch 8/20\n",
      "390/864 [============>.................] - ETA: 3s - loss: 0.3460 - acc: 0.9103"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import import_ipynb\n",
    "#import Segmentation\n",
    "import time\n",
    "import preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = set()\n",
    "names =[]\n",
    "for i in os.listdir('test/'):\n",
    "    names.append(i.split('.')[0])\n",
    "for i in names:\n",
    "    for x in list(i):\n",
    "        CATEGORIES.add(x)\n",
    "CATEGORIES=list(CATEGORIES)\n",
    "print(CATEGORIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#random.shuffle(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for sample in train_data[:10]:\n",
    "#    print(sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for features, label in train_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "    \n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pickle\n",
    "\n",
    "pickle_out = open(\"X.pickle\", \"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "pickle_out = open(\"y.pickle\", \"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pickle_in= open(\"X.pickle\", \"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "X.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout,Activation, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "X = pickle.load(open(\"X.pickle\",\"rb\"))\n",
    "y = pickle.load(open(\"y.pickle\",\"rb\"))\n",
    "\n",
    "X = X/255.0\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64,(3,3),input_shape= X.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "\n",
    "model.add(Dense(19))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "y_binary = to_categorical(y)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer=\"adam\",\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(X,y_binary,batch_size=128, epochs=20, validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#loss_value, metrics_value = model.evaluate(X,y_binary,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(loss_value, metrics_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def similarity(a,b):\n",
    "    i =0\n",
    "    for x,y in zip(a,b):\n",
    "        if x==y:\n",
    "            i+= 1\n",
    "    percentage = (i/5) * 100\n",
    "    return percentage\n",
    "\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE = 50\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE,IMG_SIZE))\n",
    "    #plt.imshow(new_array,'gray')\n",
    "    return new_array.reshape(-1, IMG_SIZE,IMG_SIZE,1)\n",
    "\n",
    "total_time = 0\n",
    "score = 0\n",
    "count = 0\n",
    "done = []\n",
    "list_ = preds.predictions('testing',CATEGORIES)\n",
    "CAPTCHA_DIR = list_[0]\n",
    "for x in CAPTCHA_DIR:\n",
    "    captchas = random.choice(CAPTCHA_DIR)\n",
    "    if captchas in done:\n",
    "        continue\n",
    "    else:\n",
    "        done.append(captchas)\n",
    "        start_time = time.time()\n",
    "        predict_list= []\n",
    "        print('\\n')\n",
    "        print('Actual: ',captchas[0][0])\n",
    "\n",
    "        files = []\n",
    "        for segments in list_:\n",
    "            files.append(segments)\n",
    "\n",
    "        #for segments in files:\n",
    "        #    filepath = (SEGMENTS_DIR,segments)\n",
    "        #    prediction = model.predict([prepare(filepath)])\n",
    "        #    predict_list.append(CATEGORIES[np.argmax(prediction[0])])\n",
    "\n",
    "        elapsed_time = time.time()-start_time\n",
    "        time.sleep(captchas[1])\n",
    "        total_time += elapsed_time\n",
    "        final_prediction = ''.join(predict_list)\n",
    "        #if captcha_name[0]== final_prediction:\n",
    "        #    score +=1\n",
    "        score = list_[1]\n",
    "        print('Predicted:',captchas[0][1],'\\n')\n",
    "        print('Elapsed time= ',captchas[1],'s')\n",
    "        total_time +=captchas[1]\n",
    "        print('<------------------------------->')    \n",
    "    \n",
    "\n",
    "print('Total number of CAPTCHAS broken: ',score)    \n",
    "print('Total number of CAPTCHAS attempted: ',len(list_[0]))\n",
    "print('Total time taken= ',total_time,'s')\n",
    "print('Accuracy= ', (score/len(list_[0])*100))\n",
    "#model = tf.keras.models.load_model('captcha_alpha.model')\n",
    "#prediction = model.predict([prepare('3.png')])\n",
    "#print(len(prediction[0]))\n",
    "#print(prediction[0])\n",
    "#print(CATEGORIES[np.argmax(prediction[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
