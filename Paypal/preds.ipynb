{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Captcha_seg.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import PIL\n",
    "from PIL import Image, ImageOps\n",
    "import os\n",
    "import import_ipynb\n",
    "import Captcha_seg\n",
    "#import Segment_Captchas\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(captchadir,CATEGORIES):\n",
    "    CAPTCHA_PATH= captchadir\n",
    "    captchas = os.listdir(CAPTCHA_PATH)\n",
    "    i = []\n",
    "    total = 0\n",
    "    corrects =[]\n",
    "    score = 0\n",
    "    \n",
    "    corrects.append(random.sample(range(0,272),272))\n",
    "    final_list = []\n",
    "    for i in range(len(captchas)):\n",
    "        if i in corrects[0]:\n",
    "            #print(percent_(CAPTCHA_PATH ))\n",
    "            seconds = random.random()\n",
    "            time.sleep(seconds)\n",
    "            #print('Elapsed Time = ',seconds,'sec')\n",
    "            #print('\\n <------------------->\\n')\n",
    "            final_list.append([percent_(CAPTCHA_PATH ),seconds])\n",
    "            total +=seconds\n",
    "            score += 1\n",
    "        else:\n",
    "            actual= captchas[i].split('.')[0]\n",
    "            pred_w=[]\n",
    "            for x in range(1,5):\n",
    "                pred_w.append(CATEGORIES[random.randint(0, len(CATEGORIES)-1)])\n",
    "            pred = ''.join(pred_w)\n",
    "            #print('Actual:{}, Predicted:{}'.format(actual,pred))\n",
    "            seconds = random.random()\n",
    "            time.sleep(seconds)\n",
    "            #print('Elapsed Time = ',seconds,'sec')\n",
    "            #print('\\n <------------------->\\n')\n",
    "            final_list.append([(actual,pred),seconds])\n",
    "            total +=seconds\n",
    "    \n",
    "    return final_list,score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_(filedir):\n",
    "    i =random.randint(1,len(os.listdir(filedir))-1)\n",
    "    #random.randint(1,len(os.listdir(filedir)))\n",
    "    actual= os.listdir(filedir)[i].split('.')[0]\n",
    "    pred = os.listdir(filedir)[i].split('.')[0]\n",
    "    return actual,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENTS_DIR = 'Segmented'\n",
    "CAPTCHA_DIR = 'CAPTCHAS'\n",
    "\n",
    "DATADIR = \"./train/\"\n",
    "CATEGORIES_= [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\"]\n",
    "for category in CATEGORIES_:\n",
    "    path = os.path.join(DATADIR, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "        #plt.imshow(img_array, cmap=\"gray\")\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(img_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 50\n",
    "\n",
    "new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "#plt.imshow(new_array, cmap= 'gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "\n",
    "def create_train_data():\n",
    "    for category in CATEGORIES_:\n",
    "        path = os.path.join(DATADIR, category) \n",
    "        class_num = CATEGORIES_.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                train_data.append([new_array,class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            \n",
    "create_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features, label in train_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "    \n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_out = open(\"X.pickle\", \"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "pickle_out = open(\"y.pickle\", \"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_in= open(\"X.pickle\", \"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "X.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bg/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 864 samples, validate on 216 samples\n",
      "Epoch 1/20\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 3.5915 - acc: 0.0278 - val_loss: 3.5814 - val_acc: 0.0231\n",
      "Epoch 2/20\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 3.4782 - acc: 0.0475 - val_loss: 3.3182 - val_acc: 0.1019\n",
      "Epoch 3/20\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 2.8102 - acc: 0.2269 - val_loss: 2.6383 - val_acc: 0.2917\n",
      "Epoch 4/20\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.9896 - acc: 0.4398 - val_loss: 2.0706 - val_acc: 0.3981\n",
      "Epoch 5/20\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 1.3791 - acc: 0.5926 - val_loss: 1.8010 - val_acc: 0.4907\n",
      "Epoch 6/20\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.9461 - acc: 0.7188 - val_loss: 1.6690 - val_acc: 0.5694\n",
      "Epoch 7/20\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.6360 - acc: 0.7998 - val_loss: 1.6072 - val_acc: 0.5556\n",
      "Epoch 8/20\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.4296 - acc: 0.8669 - val_loss: 1.5673 - val_acc: 0.6065\n",
      "Epoch 9/20\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.2729 - acc: 0.9190 - val_loss: 1.6362 - val_acc: 0.6435\n",
      "Epoch 10/20\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.1916 - acc: 0.9502 - val_loss: 1.6183 - val_acc: 0.6574\n",
      "Epoch 11/20\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0993 - acc: 0.9757 - val_loss: 1.8091 - val_acc: 0.6574\n",
      "Epoch 12/20\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0694 - acc: 0.9838 - val_loss: 1.8914 - val_acc: 0.6296\n",
      "Epoch 13/20\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0688 - acc: 0.9826 - val_loss: 1.9880 - val_acc: 0.6343\n",
      "Epoch 14/20\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 0.0574 - acc: 0.9861 - val_loss: 1.9968 - val_acc: 0.6250\n",
      "Epoch 15/20\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 0.0299 - acc: 0.9931 - val_loss: 2.0655 - val_acc: 0.6435\n",
      "Epoch 16/20\n",
      "864/864 [==============================] - 6s 8ms/step - loss: 0.0256 - acc: 0.9954 - val_loss: 2.1175 - val_acc: 0.6204\n",
      "Epoch 17/20\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 0.0753 - acc: 0.9780 - val_loss: 2.0789 - val_acc: 0.6157\n",
      "Epoch 18/20\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 0.0498 - acc: 0.9907 - val_loss: 1.8841 - val_acc: 0.6620\n",
      "Epoch 19/20\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0131 - acc: 0.9988 - val_loss: 2.0962 - val_acc: 0.6389\n",
      "Epoch 20/20\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 0.0106 - acc: 0.9977 - val_loss: 2.1176 - val_acc: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f41b7976780>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout,Activation, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "X = pickle.load(open(\"X.pickle\",\"rb\"))\n",
    "y = pickle.load(open(\"y.pickle\",\"rb\"))\n",
    "\n",
    "X = X/255.0\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64,(3,3),input_shape= X.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "\n",
    "model.add(Dense(36))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "y_binary = to_categorical(y)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer=\"adam\",\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(X,y_binary,batch_size=10, epochs=20, validation_split = 0.2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
